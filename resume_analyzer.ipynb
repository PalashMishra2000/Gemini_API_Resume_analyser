{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting Pillow>=9.1 (from pdfplumber)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Collecting charset-normalizer>=2.0.0 (from pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\palamish\\appdata\\roaming\\python\\python313\\site-packages (from pytesseract) (25.0)\n",
      "Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.6/5.6 MB 6.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.9/5.6 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.0/5.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.3/3.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.6/3.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.6/7.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.2/7.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/7.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.1/2.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, Pillow, charset-normalizer, pytesseract, pdf2image, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "\n",
      "   ----------------------------------------  0/10 [pypdfium2]\n",
      "   ---- -----------------------------------  1/10 [pycparser]\n",
      "   -------- -------------------------------  2/10 [Pillow]\n",
      "   -------- -------------------------------  2/10 [Pillow]\n",
      "   -------- -------------------------------  2/10 [Pillow]\n",
      "   -------- -------------------------------  2/10 [Pillow]\n",
      "   -------- -------------------------------  2/10 [Pillow]\n",
      "   ------------ ---------------------------  3/10 [charset-normalizer]\n",
      "   ------------------------ ---------------  6/10 [cffi]\n",
      "   ---------------------------- -----------  7/10 [cryptography]\n",
      "   ---------------------------- -----------  7/10 [cryptography]\n",
      "   ---------------------------- -----------  7/10 [cryptography]\n",
      "   ---------------------------- -----------  7/10 [cryptography]\n",
      "   -------------------------------- -------  8/10 [pdfminer.six]\n",
      "   -------------------------------- -------  8/10 [pdfminer.six]\n",
      "   -------------------------------- -------  8/10 [pdfminer.six]\n",
      "   ------------------------------------ ---  9/10 [pdfplumber]\n",
      "   ---------------------------------------- 10/10 [pdfplumber]\n",
      "\n",
      "Successfully installed Pillow-11.3.0 cffi-1.17.1 charset-normalizer-3.4.2 cryptography-45.0.5 pdf2image-1.17.0 pdfminer.six-20250506 pdfplumber-0.11.7 pycparser-2.22 pypdfium2-4.30.0 pytesseract-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Try direct text extraction\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction failed: {e}\")\n",
    "\n",
    "    # Fallback to OCR for image-based PDFs\n",
    "    print(\"Falling back to OCR for image-based PDF.\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_string(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"OCR failed: {e}\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "Palash Mishra\n",
      "BERUFSERFAHRUNG\n",
      "Magna Böco\n",
      "Werkstudent\n",
      "09/2023 – Heute | Wuppertal, Deutschland\n",
      "Unterstützung bei IT- und\n",
      "•\n",
      "Prozessoptimierungsprojekten.\n",
      "Zusammenarbeit mit interdisziplinären Teams im\n",
      "•\n",
      "Rahmen von Digitalisierungs- und\n",
      "Transformationsinitiativen.\n",
      "Basic Anwendung von Projektmanagement-\n",
      "palashmishra2000@gmail.com •\n",
      "Methoden und Einblick in IT-Systeme entlang der\n",
      "015124429678 automobilen Lieferkette\n",
      "Erwerb wertvoller Erfahrungen bei einem führenden\n",
      "Gambriniusstraße 10, 42119 •\n",
      "Tier-1-Zulieferer der Automobilindustrie.\n",
      "Wuppertal\n",
      "04.02.2000 Zen Jobs (Teilzeit)\n",
      "Aushilfe\n",
      "Indien\n",
      "11/2021 – 08/2023 | Wuppertal/Düsseldorf, Deutschland\n",
      "Ausführung verschiedener Teilzeitjobs in\n",
      "•\n",
      "unterschiedlichen Branchen, darunter Einzelhandel,\n",
      "FÄHIGKEITEN Logistik, Gastronomie und mehr.\n",
      "Sammeln von Erfahrungen in dynamischen und\n",
      "•\n",
      "C, C++, Java, Python(Tensorflow, vielfältigen Arbeitsumfeldern in Deutschland.\n",
      "Pandas), HTML, SQL, Microsoft 365 Verbesserung der deutschen Sprachkenntnisse und\n",
      "•\n",
      "Services, Microsoft Azure, Excel VBA, der Kommunikationsfähigkeiten durch\n",
      "MS Power Automate, kontinuierlichen Kunden- und Teamkontakt.\n",
      "Projectmanagement Tools (Jira)\n",
      "KURSE UND PROJEKTE\n",
      "EDUCATION\n",
      "Supervised Machine Learning: Regression and\n",
      "BSc. Informatik mit anwendungsfach Classification by Deeplearning.AI and Stanford\n",
      "Wirtschaftswissenschaft\n",
      "Bergische Universität Wuppertal Verteiltes rechnen mit OpenMPI\n",
      "2021 – Heute | Wuppertal, Deutschland\n",
      "Socket Programmierung in C\n",
      "Studienkolleg\n",
      "Grundlagen der Netzwerkanalyse Teil 1 (TCP/IP,\n",
      "Studienkolleg Bonn\n",
      "UDP/IP, und andere Protokollen)\n",
      "2019 – 2020 | Bonn, Deutschland\n",
      "Netzwerkberechnung, Subnetting und\n",
      "Netzwerksimulation\n",
      "PROFILE\n",
      "Gruppenprojekt - Entwicklung eines 2D-Spiels in Java.\n",
      "Als motivierter Wirtschaftsinformatik-\n",
      "Projektmanagement über Git und Jira.\n",
      "Student vereine ich mein Wissen in\n",
      "Informatik und Betriebswirtschaft mit\n",
      "starker Kommunikationsfähigkeit.\n",
      "LANGUAGES\n",
      "Meine Leidenschaft für Datenanalyse,\n",
      "Geschäftsprozesse und das Verfolgen\n",
      "Englisch\n",
      "der neuesten technologischen Trends\n",
      "machen mich zu einem idealen\n",
      "Deutsch\n",
      "Kandidaten, um von den Besten zu\n",
      "Telc C1 Hochschule\n",
      "lernen und mein Potenzial voll\n",
      "auszuschöpfen.\n",
      "Hindi\n",
      "Marathi\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Google GenerativeAI Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Downloading google_api_python_client-2.177.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google.generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google.generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google.generativeai) (4.14.1)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting requests<3.0.0,>=2.18.0 (from google-api-core->google.generativeai)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.8.3)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google.generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google.generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google.generativeai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\palamish\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.5 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.6/4.5 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.4/4.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.4/4.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.5/4.5 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading google_api_python_client-2.177.0-py3-none-any.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/13.7 MB 6.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.6/13.7 MB 6.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.9/13.7 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.2/13.7 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.8/13.7 MB 6.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.1/13.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.7/13.7 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.0/13.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.6/13.7 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.7/13.7 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: urllib3, uritemplate, python-dotenv, pyparsing, pyasn1, protobuf, grpcio, cachetools, rsa, requests, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "\n",
      "   ----------------------------------------  0/21 [urllib3]\n",
      "   ----- ----------------------------------  3/21 [pyparsing]\n",
      "   ------- --------------------------------  4/21 [pyasn1]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   ----------- ----------------------------  6/21 [grpcio]\n",
      "   ----------- ----------------------------  6/21 [grpcio]\n",
      "   --------------- ------------------------  8/21 [rsa]\n",
      "   ----------------- ----------------------  9/21 [requests]\n",
      "   ------------------- -------------------- 10/21 [pyasn1-modules]\n",
      "   ------------------- -------------------- 10/21 [pyasn1-modules]\n",
      "   ------------------- -------------------- 10/21 [pyasn1-modules]\n",
      "   -------------------- ------------------- 11/21 [proto-plus]\n",
      "   ---------------------- ----------------- 12/21 [httplib2]\n",
      "   ------------------------ --------------- 13/21 [googleapis-common-protos]\n",
      "   ------------------------ --------------- 13/21 [googleapis-common-protos]\n",
      "   ---------------------------- ----------- 15/21 [google-auth]\n",
      "   ---------------------------- ----------- 15/21 [google-auth]\n",
      "   ---------------------------- ----------- 15/21 [google-auth]\n",
      "   -------------------------------- ------- 17/21 [google-api-core]\n",
      "   -------------------------------- ------- 17/21 [google-api-core]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ---------------------------------- ----- 18/21 [google-api-python-client]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   ----------------------------------- --- 19/21 [google-ai-generativelanguage]\n",
      "   -------------------------------------- - 20/21 [google.generativeai]\n",
      "   -------------------------------------- - 20/21 [google.generativeai]\n",
      "   -------------------------------------- - 20/21 [google.generativeai]\n",
      "   -------------------------------------- - 20/21 [google.generativeai]\n",
      "   ---------------------------------------- 21/21 [google.generativeai]\n",
      "\n",
      "Successfully installed cachetools-5.5.2 google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.177.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 google.generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.74.0 grpcio-status-1.71.2 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pyparsing-3.2.3 python-dotenv-1.1.1 requests-2.32.4 rsa-4.9.1 uritemplate-4.2.0 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of India?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The capital of India is **New Delhi**.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.005780728161334991\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 10,\n",
      "        \"total_token_count\": 17\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume(resume_text, job_description=None):\n",
    "    if not resume_text:\n",
    "        return {\"error\": \"Resume text is required for analysis.\"}\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "    \n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced HR with Technical Experience in the field of any one job role from Data Science, Data Analyst, DevOPS, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Development, Big Data Engineering, Marketing Analyst, Human Resource Manager, Software Developer your task is to review the provided resume.\n",
    "    Please share your professional evaluation on whether the candidate's profile aligns with the role.ALso mention Skills he already have and siggest some skills to improve his resume , also suggest some course he might take to improve the skills.Highlight the strengths and weaknesses.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    if job_description:\n",
    "        base_prompt += f\"\"\"\n",
    "        Additionally, compare this resume to the following job description:\n",
    "        \n",
    "        Job Description:\n",
    "        {job_description}\n",
    "        \n",
    "        Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(base_prompt)\n",
    "\n",
    "    analysis = response.text.strip()\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Resume Evaluation: Palash Mishra\n",
      "\n",
      "**Role Assumed for Evaluation:** Data Analyst\n",
      "\n",
      "This evaluation assesses Palash Mishra's resume against a Data Analyst role.  My background is in Data Science, providing context to my analysis.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Education:** A BSc in Informatics with a specialization in Business Administration (Wirtschaftswissenschaft) is a solid foundation for a Data Analyst role.  The coursework suggests a good understanding of programming and data analysis principles.\n",
      "* **Programming Skills:** Palash demonstrates proficiency in several relevant programming languages: C, C++, Java, Python (including TensorFlow and Pandas), and SQL. This is a significant strength.  The mention of Excel VBA further highlights his practical skills.\n",
      "* **Project Experience:** The supervised machine learning project (Regression and Classification) and the 2D game development project in Java demonstrate practical application of his skills.  The mention of Git and Jira indicates experience with version control and project management.\n",
      "* **Work Experience (Magna Böco):** The Werkstudent position at Magna Böco, a leading Tier-1 automotive supplier, carries significant weight.  His involvement in IT and process optimization projects within a large, established company is impressive for a student.\n",
      "* **Languages:** Fluency in German (Telc C1 Hochschule) is a major asset, particularly given the location of his work experience.\n",
      "\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "* **Lack of Quantifiable Achievements:** The resume lacks specific quantifiable achievements in his work experience.  For example, instead of \"Support in IT and process optimization projects,\" it would be much stronger to state something like, \"Reduced process X by Y% through the implementation of Z solution.\" This is crucial for demonstrating impact.\n",
      "* **Vague Work Experience (Zen Jobs):** The description of his part-time jobs at Zen Jobs is too generic. While it shows adaptability and work ethic, it doesn't directly contribute to his suitability for a data analyst role.\n",
      "* **Limited Data Analysis Project Detail:**  While the supervised machine learning project is mentioned, there's no detail about the dataset used, the methodology employed, or the results achieved. This section needs significant expansion.\n",
      "* **Missing Data Visualization Skills:** The resume doesn't explicitly mention any experience with data visualization tools like Tableau, Power BI, or Matplotlib/Seaborn. This is a crucial skill for a Data Analyst.\n",
      "* **Resume Structure & Presentation:** The German/English mix needs consistency.  A completely English resume would be preferable for international job applications. The formatting could also be improved for better readability.\n",
      "\n",
      "\n",
      "**Skills to Improve:**\n",
      "\n",
      "* **Data Visualization:**  Mastering at least one data visualization tool (Tableau, Power BI, or Python libraries like Matplotlib/Seaborn) is essential.\n",
      "* **Data Wrangling & Cleaning:**  Demonstrate proficiency in cleaning and transforming data using Python libraries like Pandas or SQL.\n",
      "* **Statistical Analysis:**  Strengthen his understanding and application of statistical methods relevant to data analysis (e.g., hypothesis testing, regression analysis).\n",
      "* **Data Storytelling & Communication:**  Improve the ability to present data insights effectively through clear visualizations and concise written/verbal communication.\n",
      "* **Big Data Technologies (Optional but beneficial):** Familiarity with tools like Spark or Hadoop would enhance his profile.\n",
      "\n",
      "\n",
      "**Suggested Courses:**\n",
      "\n",
      "* **Data Visualization with Tableau/Power BI:** Online courses on platforms like Udemy, Coursera, or DataCamp.\n",
      "* **Data Wrangling with Python (Pandas):** Similar online courses focusing on data manipulation and cleaning.\n",
      "* **Statistical Analysis for Data Science:** Courses on Coursera or edX covering hypothesis testing, regression, and other relevant techniques.\n",
      "* **SQL for Data Analysis:** Many online resources offer SQL tutorials and certifications.\n",
      "* **Communicating Data Insights:**  Courses or workshops focusing on data storytelling and presentation skills.\n",
      "\n",
      "**Overall Assessment:**\n",
      "\n",
      "Palash has a solid foundation for a Data Analyst role, particularly given his programming skills and experience at Magna Böco. However, he needs to strengthen his resume by quantifying his achievements, highlighting his data analysis skills with specific projects, and adding data visualization expertise.  The suggested improvements and courses would significantly enhance his candidacy.  Focusing on quantifiable results and showcasing projects is key to making his resume stand out.\n"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
